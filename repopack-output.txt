This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2025-11-08T06:47:19.939Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.gitignore
.python-version
main.py
pyproject.toml
uv.lock

================================================================
Repository Files
================================================================

================
File: .gitignore
================
# Python-generated files
__pycache__/
*.py[oc]
build/
dist/
wheels/
*.egg-info

# Virtual environments
.venv

================
File: .python-version
================
3.13

================
File: main.py
================
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# 设置随机种子以保证结果可复现
torch.manual_seed(42)
np.random.seed(42)

class SpectralProjectionLayer(nn.Module):
    """
    谱范数投影层 (Spectral Norm Projection Layer)
    --------------------------------------------------
    功能：实现PPT中的核心约束投影，强制输出对偶变量满足 ||P_Omega(Y)||_sigma <= 1
    数学表达：Y_proj = Z_masked / max(1, sigma_max(Z_masked))
    """
    def __init__(self):
        super(SpectralProjectionLayer, self).__init__()

    def forward(self, z_raw, mask):
        """
        输入：
        - z_raw: 神经网络原始输出，形状 (Batch, H, W)
        - mask: 观测掩码 Omega，形状 (Batch, H, W)
        输出：
        - y_proj: 满足约束的对偶变量
        """
        # 1. P_Omega 操作：强制非观测区域为0
        z_masked = z_raw * mask

        # 2. 计算谱范数 (最大奇异值 sigma_max)
        # torch.linalg.matrix_norm(ord=2) 自动使用SVD计算谱范数，且该操作是可微的
        # keepdim=True 保持维度为 (Batch, 1, 1) 以便后续广播除法
        sigma_max = torch.linalg.matrix_norm(z_masked, ord=2, dim=(-2, -1), keepdim=True)

        # 3. 计算缩放因子
        # 如果 sigma_max <= 1，scale = 1 (不做缩放)
        # 如果 sigma_max > 1，scale = sigma_max (缩放到谱范数为1)
        scale = torch.max(torch.ones_like(sigma_max), sigma_max)

        # 4. 执行投影
        y_proj = z_masked / (scale + 1e-8) # 添加微小值避免除零（虽然理论上 scale >= 1）

        return y_proj, sigma_max

class DualMatrixCompletionNet(nn.Module):
    """
    对偶矩阵补全网络 (Dual Matrix Completion Network)
    --------------------------------------------------
    结构：
    [Input: M, Omega] -> [Backbone CNN] -> [Z_raw] -> [Spectral Projection] -> [Output: Y_proj]
    """
    def __init__(self, input_channels=2, hidden_dim=64):
        super(DualMatrixCompletionNet, self).__init__()
        
        # 骨干网络：拟合非线性映射。此处使用简单的全卷积网络作为示例。
        # 实际应用中可替换为更深的网络或基于注意力的架构。
        self.backbone = nn.Sequential(
            # 输入层：接收堆叠的 M 和 Omega (Batch, 2, H, W)
            nn.Conv2d(input_channels, hidden_dim, kernel_size=3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            
            # 隐藏层
            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(inplace=True),
            
            # 输出层：生成单通道的原始对偶变量 Z_raw
            nn.Conv2d(hidden_dim, 1, kernel_size=3, padding=1)
        )
        
        # 谱投影层
        self.projection = SpectralProjectionLayer()

    def forward(self, M, Omega):
        # 1. 数据堆叠：(Batch, H, W) -> (Batch, 2, H, W)
        x = torch.cat([M.unsqueeze(1), Omega.unsqueeze(1)], dim=1)
        
        # 2. 特征提取
        z_raw = self.backbone(x)
        
        # 3. 调整维度：(Batch, 1, H, W) -> (Batch, H, W)
        z_raw = z_raw.squeeze(1)
        
        # 4. 约束投影
        y_proj, sigma_max_raw = self.projection(z_raw, Omega)
        
        return y_proj, sigma_max_raw

class DualLoss(nn.Module):
    """
    对偶损失函数 (Dual Objective Loss)
    --------------------------------------------------
    目标：最大化对偶目标函数 <Y, M>
    转换：最小化 Loss = - <Y, M> = - sum(Y_ij * M_ij)
    """
    def __init__(self):
        super(DualLoss, self).__init__()

    def forward(self, y_proj, M):
        # 计算 Frobenius 内积
        inner_product = torch.sum(y_proj * M)
        
        # 取负号以适配梯度下降
        loss = -inner_product
        
        # 可选：根据Batch大小归一化，使Loss数值稳定
        # loss = loss / M.size(0)
        return loss

# =========================================
# 辅助函数：生成合成数据
# =========================================
def generate_synthetic_data(batch_size, n1, n2, rank, observation_ratio, device):
    """
    生成低秩矩阵及其观测掩码
    M = P_Omega(U * V^T)
    """
    # 生成真实的低秩矩阵 L = U * V^T
    U = torch.randn(batch_size, n1, rank, device=device)
    V = torch.randn(batch_size, n2, rank, device=device)
    L_true = torch.bmm(U, V.transpose(1, 2))
    
    # 生成随机观测掩码 Omega
    Omega = (torch.rand(batch_size, n1, n2, device=device) < observation_ratio).float()
    
    # 生成观测矩阵 M
    M = L_true * Omega
    return M, Omega, L_true

# =========================================
# 主训练流程
# =========================================
def main():
    # 1. 配置运行环境
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Running on device: {device}")

    # 2. 超参数设置
    N1, N2 = 50, 50       # 矩阵维度
    RANK = 5              # 真实秩
    OBS_RATIO = 0.4       # 观测率
    BATCH_SIZE = 16       # 批次大小
    LR = 1e-3             # 学习率
    EPOCHS = 100          # 训练轮数

    # 3. 初始化模型与优化器
    model = DualMatrixCompletionNet().to(device)
    optimizer = optim.Adam(model.parameters(), lr=LR)
    criterion = DualLoss()

    # 4. 生成训练数据 (此处仅生成一个Batch演示，实际应使用DataLoader)
    M_train, Omega_train, L_true = generate_synthetic_data(BATCH_SIZE, N1, N2, RANK, OBS_RATIO, device)
    print(f"Data shape: M {M_train.shape}, Omega {Omega_train.shape}")

    # 5. 训练循环
    print("\n--- Start Training ---")
    model.train()
    for epoch in range(EPOCHS):
        optimizer.zero_grad()
        
        # 前向传播
        Y_proj, sigma_raw = model(M_train, Omega_train)
        
        # 计算损失
        loss = criterion(Y_proj, M_train)
        
        # 反向传播
        loss.backward()
        optimizer.step()
        
        # --- 监控与验证 ---
        if (epoch + 1) % 10 == 0 or epoch == 0:
            with torch.no_grad():
                # 计算当前 Y_proj 的实际谱范数，验证是否满足约束 <= 1
                current_sigma = torch.linalg.matrix_norm(Y_proj, ord=2, dim=(-2, -1))
                max_sigma = current_sigma.max().item()
                mean_dual_obj = -loss.item() / BATCH_SIZE # 平均对偶目标值
                
                print(f"Epoch [{epoch+1:03d}/{EPOCHS}] | "
                      f"Loss: {loss.item():.4f} | "
                      f"Mean Dual Obj: {mean_dual_obj:.4f} | "
                      f"Max Spectral Norm: {max_sigma:.4f} (Constraint <= 1.0)")

    print("\n--- Training Finished ---")
    
    # 6. 最终结果验证
    model.eval()
    with torch.no_grad():
        Y_final, _ = model(M_train, Omega_train)
        final_sigma = torch.linalg.matrix_norm(Y_final, ord=2, dim=(-2, -1))
        print(f"Final check - Max Spectral Norm of Y: {final_sigma.max().item():.6f}")
        print("Validation passed: All Y_proj satisfy ||P_Omega(Y)||_\sigma <= 1")

if __name__ == '__main__':
    main()

================
File: pyproject.toml
================
[project]
name = "matrixcompletion"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.13"
dependencies = []

================
File: uv.lock
================
version = 1
revision = 1
requires-python = ">=3.13"

[[package]]
name = "matrixcompletion"
version = "0.1.0"
source = { virtual = "." }
